# GEOL0069_Week4

<!-- GETTING STARTED -->
## Getting Started

The Week 4 assignment for GEOL0069 Artificial Intelligence for Earth Observation focuses on applying unsupervised learning to a real Earth-observation problem: classifying Sentinel-3 SAR altimetry echoes over polar regions. Each radar measurement contains a returned “echo”  whose shape depends on surface type. In sea-ice zones, echoes can come from sea ice or from leads.  

In this project, we extract a small set of waveform-derived features, then use clustering to separate echoes into two groups. I then summarise the two classes by computing an mean echo shape and a standard deviation envelope. Finally, I evaluate how well the unsupervised clusters match the ESA official classification using a confusion matrix. 

<!-- PREREQUISITES -->
## Prerequisites

Run the notebook in Google Colab.
- Install packages
  ```sh
  !pip install netCDF4
  ```
  ```sh
  !pip install rasterio
  ```
* Mounting Google Drive on Google Colab
  ```sh
  from google.colab import drive
  drive.mount('/content/drive')
  ```

<!-- INTRODUCTION -->
## Introduction to unsupervised learning: K-means Clustering

### What K-means does
K-means is one of the most widely used unsupervised clustering algorithms and provides a clear baseline for thinking about how clustering works. The idea is to partition the dataset into K clusters such that points inside the same cluster are as similar as possible, while points in different clusters are as different as possible. It does this by learning K centroids.

### How the algorithm works
- Each observation is assigned to the closest centroid, and then the centroids are updated to be the mean of the points assigned to them. - This “assign → update” cycle repeats until assignments stop changing or a maximum number of iterations is reached.

### Strengths and limitations for altimetry echoes
- K-means is computationally efficient and easy to implement, but it has limitations that matter for geophysical data.
- It assumes clusters are roughly spherical in feature space and similar in size, and it assigns each point to exactly one cluster.
- The choice of K is also user-defined, so you must decide how many groups exist in advance. In this assignment, while K-means is useful conceptually, a probabilistic approach (GMM) can be more flexible for separating sea-ice and lead populations whose spreads may differ.

## Unsupervised Learning: Gaussian Mixture Models (GMM)

### What a GMM does
- A Gaussian Mixture Model (GMM) treats the dataset as being generated by a mixture of several Gaussian distributions (components). Unlike K-means, which uses only distances to centroids, GMM is probabilistic: each data point receives a probability of belonging to each component.
- This is useful when clusters overlap or have different shapes/spreads. Each Gaussian component has its own mean and covariance, meaning GMM can represent elongated or uneven clusters more naturally than K-means.

### Expectation–Maximization (EM) in practice
- Model parameters are learned using the Expectation–Maximization (EM) algorithm.
- In the E-step, the algorithm estimates membership probabilities for each point. In the M-step, it updates the Gaussian parameters to maximise the likelihood given those responsibilities. This iterative process continues until convergence.

### Why GMM is suitable for sea ice vs lead separation
- In this project, I use a 2-component GMM because the target separation is binary: sea ice vs lead. The input to the model is not the raw waveform but a small set of waveform-derived features.
- After fitting the GMM, each echo is assigned to one of two clusters, which are then interpreted as sea-ice or lead based on the waveform characteristics.

Below is a basic code implementation for a Gaussian Mixture Model.

```sh
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
import numpy as np
import os

# Sample data
X = np.random.rand(100, 2)

# GMM model
gmm = GaussianMixture(n_components=3)
gmm.fit(X)
y_gmm = gmm.predict(X)

# Plotting
plt.scatter(X[:, 0], X[:, 1], c=y_gmm, cmap='viridis')
centers = gmm.means_
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)
plt.title('Gaussian Mixture Model')
```

![Gaussian Mixture Model](GMM.png)

## Running the GMM Model

### Feature preparation and cleaning
- In the notebook, each echo is represented by a compact feature vector (e.g., sig0, peakiness, and SSD).
- These variables are stacked into a feature matrix and then standardised so that features with different numeric ranges contribute fairly to the clustering.
- Any rows containing NaN values are removed, and the dataset is restricted to echoes with ESA surface classes relevant to this task.

### Fitting and predicting clusters
A 2-component Gaussian Mixture Model is then fitted to the cleaned feature matrix. The trained model predicts a cluster label (0/1) for each echo, which is later interpreted as sea ice or lead by inspecting waveform shapes and comparing against ESA labels.

## Results: overview
- This section summarises the main outcomes of the unsupervised classification.
- First, we compare the average echo shape and standard deviation between the two classes.
- Next, we visualise example echoes from each class to support the interpretation of “sea ice” versus “lead”.
- We also include waveform alignment examples to show why alignment can produce cleaner class averages.
- Finally, we evaluate agreement with ESA official labels using a confusion matrix.

### Mean and Standard Deviation Echo Shape (Sea Ice vs Lead)

The means and standard deviation of the sea ice and lead echos are calculated and plotted using the code below. 

```sh
mean_ice = np.mean(waves_cleaned[clusters_gmm==0],axis=0)
std_ice = np.std(waves_cleaned[clusters_gmm==0], axis=0)

plt.plot(mean_ice, label='ice')
plt.fill_between(range(len(mean_ice)), mean_ice - std_ice, mean_ice + std_ice, alpha=0.3)


mean_lead = np.mean(waves_cleaned[clusters_gmm==1],axis=0)
std_lead = np.std(waves_cleaned[clusters_gmm==1], axis=0)

plt.plot(mean_lead, label='lead')
plt.fill_between(range(len(mean_lead)), mean_lead - std_lead, mean_lead + std_lead, alpha=0.3)

plt.title('Plot of mean and standard deviation for each class')
plt.legend()
```

![Plot of mean and standard deviation for each class](mean_std_shape.png)

- The plot above summarises the two clustered classes by showing the mean waveform for each class, together with a ±1σ standard deviation envelope. The mean provides a “typical” echo shape for the class, while the standard deviation highlights how variable echoes are within that class. In general, lead echoes tend to be more peaked and specular, while sea-ice echoes often show a broader return due to rougher scattering.
- The shaded regions are important: large standard deviation indicates high intra-class variability (e.g., differing lead widths, mixed surfaces, or small shifts in peak position). This figure is the core output of the assignment because it turns thousands of individual echoes into two interpretable summary shapes.

### Example Echoes for Sea Ice and Leads

To visually check that the clustering makes physical sense, I plotted sets of individual waveforms for each class using the code below:

Lead cluster echoes:
```sh
# plot echos for the lead cluster
x = np.stack([np.arange(1,waves_cleaned[clusters_gmm==1].shape[1]+1)]*waves_cleaned[clusters_gmm==1].shape[0])
plt.plot(x,waves_cleaned[clusters_gmm==1])  # plot of all the echos
plt.title('Clusters_gmm==1(lead)')
plt.show()
```

Sea ice cluster echoes:
```sh
# plot echos for the sea ice cluster
x = np.stack([np.arange(1,waves_cleaned[clusters_gmm==0].shape[1]+1)]*waves_cleaned[clusters_gmm==0].shape[0])
plt.plot(x,waves_cleaned[clusters_gmm==0])  # plot of all the echos
plt.title('Clusters_gmm==0(sea ice)')
plt.show()
```

![Lead cluster](lead.png)

![Sea ice cluster](sea_ice.png)

- The sea-ice set typically contains echoes with a more distributed shape and a broader trailing edge, consistent with scattering from a rough or heterogeneous surface.
- The lead set is usually dominated by narrow, high-amplitude peaks that resemble specular returns from smoother open water.
- These example plots are useful because unsupervised labels (0/1) do not automatically correspond to “ice/lead” as interpreting the clusters requires checking the waveform morphology. Together, these figures provide qualitative evidence that the two clusters correspond to two distinct echo populations rather than a random split in feature space.

### Waveform Alignment (Original vs Aligned)

The alignment figures are shown below:

![Individual waveform comparison](alignent_examples.png)

- The alignment figure compares original waveforms (blue) with aligned waveforms (red dashed) for a few examples from each class.
- In real altimetry data, the main peak can appear at slightly different range bins due to tracking, noise, or surface variability. If we average many unaligned echoes, the mean peak can become “smeared,” artificially inflating the standard deviation and making class differences harder to interpret.
- Alignment shifts each waveform so its key peak (or reference location) lines up with a common bin. This makes the averaged echo shapes cleaner and ensures the mean/std summary reflects shape differences rather than simple horizontal offsets.

## Quantitative Evaluation: Confusion Matrix (ESA vs GMM)
- Finally, I compare the unsupervised GMM classification against the ESA official surface-type labels using a confusion matrix shown below:

![Confusion matrix](confusion_matrix.png)

-   The matrix counts how many echoes are assigned to each combination of (ESA truth, GMM prediction). High values along the diagonal indicate strong agreement, while off-diagonal counts represent misclassifications (e.g., ESA lead predicted as ice, or vice versa).
-   This evaluation is important because clustering alone does not guarantee the groups correspond to the desired physical classes. A good confusion matrix demonstrates that the feature set and the GMM separation capture real surface differences.
-   In this run, the matrix shows strong diagonal dominance, suggesting that the GMM clusters align well with the ESA-provided classification.

Below are the name of the Sentinel 2 and Sentinel-3 data folders that are used in this project.

- Sentinel-2 optical data : S2A_MSIL1C_20190301T235611_N0207_R116_T01WCU_20190302T014622.SAFE
- Sentinel-3 OLCI data : S3A_SR_2_LAN_SI_20190307T005808_20190307T012503_20230527T225016_1614_042_131______LN3_R_NT_005.SEN3

<!-- CONTACT -->
# Contact
Yihang Zhong - zcqshop@ucl.ac.uk

<p align="right">(<a href="#geol0069_week4">back to top</a>)</p> ```
